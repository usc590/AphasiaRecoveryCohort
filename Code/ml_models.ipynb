{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:38:49.521534Z",
     "start_time": "2024-10-15T19:37:59.699380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv  # For saving hyperparameters, predictions, and metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_data(features_file, labels_file, labels_column):\n",
    "    features_df = pd.read_csv(features_file, index_col=0)\n",
    "    labels_df = pd.read_csv(labels_file, index_col=0)\n",
    "\n",
    "    X = features_df\n",
    "    y = labels_df[labels_column]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y\n",
    "\n",
    "# Save the best hyperparameters to a CSV file\n",
    "def save_hyperparameters(model_name, best_params):\n",
    "    filename = f\"{model_name}_best_params.csv\"\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Parameter\", \"Value\"])\n",
    "        # Assuming best_params is a list of dictionaries, one for each fold\n",
    "        for params in best_params:\n",
    "            for param, value in params.items():\n",
    "                writer.writerow([param, value])\n",
    "    print(f\"Best hyperparameters for {model_name} saved to {filename}\")\n",
    "\n",
    "# Save the predictions, true labels, and metrics to a CSV file\n",
    "def save_predictions_and_metrics(model_name, y_true, y_pred, corr, rmse):\n",
    "    # Save predictions and true labels\n",
    "    predictions_filename = f\"../Results/{model_name}_predictions.csv\"\n",
    "    with open(predictions_filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"True Label\", \"Predicted Label\"])\n",
    "        writer.writerows(zip(y_true, y_pred))\n",
    "    \n",
    "    # Save correlation and RMSE metrics\n",
    "    metrics_filename = f\"../Results/{model_name}_metrics.csv\"\n",
    "    with open(metrics_filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Metric\", \"Value\"])\n",
    "        writer.writerow([\"Correlation\", corr])\n",
    "        writer.writerow([\"RMSE\", rmse])\n",
    "    \n",
    "    print(f\"Predictions for {model_name} saved to {predictions_filename}\")\n",
    "    print(f\"Metrics for {model_name} saved to {metrics_filename}\")\n",
    "\n",
    "# Perform Leave-One-Out Cross-Validation on a single model\n",
    "def run_loo_cv(model, param_grid, model_name, X, y):\n",
    "    loo = LeaveOneOut()\n",
    "    y_true, y_pred, best_params = [], [], []\n",
    "\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        y_true.append(y_test.values[0])\n",
    "        \n",
    "        if param_grid:\n",
    "            # Add n_jobs=-1 for parallel processing during Grid Search\n",
    "            grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            pred = best_model.predict(X_test)\n",
    "            best_params.append(grid_search.best_params_)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_test)\n",
    "        \n",
    "        y_pred.append(pred[0])\n",
    "    \n",
    "    corr, _ = pearsonr(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    \n",
    "    print(f\"{model_name}: Correlation (R) = {corr:.4f}, RMSE = {rmse:.4f}\")\n",
    "    \n",
    "    # Save hyperparameters, predictions, and metrics\n",
    "    if param_grid:\n",
    "        print(f\"Best hyperparameters for {model_name}: {best_params}\")\n",
    "        save_hyperparameters(model_name, best_params)\n",
    "    \n",
    "    save_predictions_and_metrics(model_name, y_true, y_pred, corr, rmse)\n",
    "\n",
    "    return best_params\n",
    "\n",
    "# Define a simple neural network architecture\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(15, 64)  # Input: 15 features, Hidden layer: 64 neurons\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)  # Output: 1 target value\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Function to run the neural network on GPU (if available) and save the metrics\n",
    "# Function to run the neural network with Leave-One-Out Cross-Validation (LOO)\n",
    "def run_neural_network(X, y):\n",
    "    # Check if a GPU is available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Initialize Leave-One-Out cross-validator\n",
    "    loo = LeaveOneOut()\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        # Split the data into training and test for this fold\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Convert to PyTorch tensors and move to GPU if available\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "        y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "        y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "        # Define the model, loss, and optimizer\n",
    "        model = NeuralNet().to(device)  # Move the model to the GPU\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Training loop (reinitialize the model for each LOO fold)\n",
    "        num_epochs = 200  # Reduced to prevent overfitting and speed up LOO\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate on the left-out test sample\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            prediction = model(X_test_tensor).cpu().numpy()[0][0]  # Get prediction and move back to CPU\n",
    "\n",
    "        # Store the true value and predicted value\n",
    "        y_true.append(y_test.values[0])\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "    # Calculate RMSE and Pearson correlation coefficient (R-value)\n",
    "    test_rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    corr = pearsonr(y_true, y_pred)\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f\"Neural Network MLP: Test RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"Neural Network MLP: Test R value (correlation): {corr[0]:.4f}\")  # Fix here\n",
    "\n",
    "    # Save predictions and metrics using the existing function\n",
    "    model_name = 'NeuralNetwork_MLP'\n",
    "    save_predictions_and_metrics(model_name, y_true, y_pred, corr[0], test_rmse)\n",
    "\n",
    "\n",
    "# Choose and run individual models\n",
    "\n",
    "def run_linear_regression(X, y):\n",
    "    model_name = 'Linear_Regression'\n",
    "    model = LinearRegression()\n",
    "    best_params = run_loo_cv(model, None, model_name, X, y)\n",
    "\n",
    "def run_ridge(X, y):\n",
    "    model_name = 'Ridge'\n",
    "    model = Ridge()\n",
    "    best_params = run_loo_cv(model, param_grids[model_name], model_name, X, y)\n",
    "\n",
    "def run_lasso(X, y):\n",
    "    model_name = 'Lasso'\n",
    "    model = Lasso()\n",
    "    best_params = run_loo_cv(model, param_grids[model_name], model_name, X, y)\n",
    "\n",
    "def run_svr(X, y):\n",
    "    model_name = 'SVR'\n",
    "    model = SVR()\n",
    "    best_params = run_loo_cv(model, param_grids[model_name], model_name, X, y)\n",
    "\n",
    "def run_random_forest(X, y):\n",
    "    model_name = 'Random Forest'\n",
    "    model = RandomForestRegressor(n_jobs=-1)  # Enable parallel processing for RandomForest\n",
    "    best_params = run_loo_cv(model, param_grids[model_name], model_name, X, y)\n",
    "\n",
    "def run_xgboost(X, y):\n",
    "    model_name = 'XGBoost'\n",
    "    model = XGBRegressor(use_label_encoder=False, eval_metric='rmse', n_jobs=-1)  # Enable parallel processing for XGBoost\n",
    "    best_params = run_loo_cv(model, param_grids[model_name], model_name, X, y)\n",
    "\n",
    "# Define parameter grids for models\n",
    "param_grids = {\n",
    "    'Ridge': {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\n",
    "    'Lasso': {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\n",
    "    'SVR': {\n",
    "        # 'C': [0.1, 1.0, 10.0, 100.0],\n",
    "        # 'epsilon': [0.001, 0.01, 0.1, 1.0],\n",
    "        # 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        # 'n_estimators': [100, 200],\n",
    "        # 'max_depth': [None, 10, 20],\n",
    "        # 'min_samples_split': [2, 5],\n",
    "        # 'min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 0.3],\n",
    "        'max_depth': [3, 5, 10],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "}\n",
    "# Main workflow\n",
    "if __name__ == '__main__':\n",
    "    features_file = '../Processed Data/rest_101_participants_40_regions.csv'\n",
    "    labels_file = '../Processed Data/101_participants_40_regions_target_variable.csv'\n",
    "    prediction_label = 'Aphasia quotient'\n",
    "    \n",
    "    X, y = load_data(features_file, labels_file, prediction_label)\n",
    "    \n",
    "    # Choose a model to run (uncomment the model you want to run)\n",
    "    #run_linear_regression(X, y)\n",
    "    # run_ridge(X, y)\n",
    "    # run_lasso(X, y)\n",
    "    run_svr(X, y)\n",
    "    run_random_forest(X, y)\n",
    "    # run_xgboost(X, y)\n",
    "    # run_neural_network(X, y)\n"
   ],
   "id": "48eb133d541e0321",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shark\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR: Correlation (R) = 0.2582, RMSE = 24.5690\n",
      "Predictions for SVR saved to ../Results/SVR_predictions.csv\n",
      "Metrics for SVR saved to ../Results/SVR_metrics.csv\n",
      "Random Forest: Correlation (R) = 0.4760, RMSE = 21.7640\n",
      "Predictions for Random Forest saved to ../Results/Random Forest_predictions.csv\n",
      "Metrics for Random Forest saved to ../Results/Random Forest_metrics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shark\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:44:28.101620Z",
     "start_time": "2024-10-15T19:44:25.501188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from PIL import Image\n",
    "\n",
    "def merge_metrics(directory):\n",
    "    metrics_list = []\n",
    "\n",
    "    # Loop through the files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('metrics.csv'):\n",
    "            # Read each metrics CSV file\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Add a column for the model name (extracted from the filename)\n",
    "            model_name = filename.replace('_metrics.csv', '')\n",
    "\n",
    "            # Extract correlation and RMSE values\n",
    "            r_corr = df.loc[df['Metric'] == 'Correlation', 'Value'].values[0]\n",
    "            rmse = df.loc[df['Metric'] == 'RMSE', 'Value'].values[0]\n",
    "\n",
    "            # Append the model name, correlation, and RMSE to the list\n",
    "            metrics_list.append({'Model': model_name, 'R corr': r_corr, 'RMSE': rmse})\n",
    "\n",
    "    # Convert the list into a DataFrame\n",
    "    all_metrics = pd.DataFrame(metrics_list)\n",
    "\n",
    "    # Save the merged metrics to a new CSV file\n",
    "    output_file = os.path.join(directory, 'merged_metrics.csv')\n",
    "    all_metrics.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Merged metrics saved to {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "def plot_predictions(directory):\n",
    "    # Loop through the files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('predictions.csv'):\n",
    "            # Read each predictions CSV file\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Extract true and predicted values\n",
    "            true_values = df['True Label'].values\n",
    "            predicted_values = df['Predicted Label'].values\n",
    "\n",
    "            # Calculate RMSE and Pearson correlation coefficient (R-value)\n",
    "            rmse = mean_squared_error(true_values, predicted_values, squared=False)\n",
    "            r_corr, _ = pearsonr(true_values, predicted_values)\n",
    "\n",
    "            # Extract model name from the filename\n",
    "            model_name = filename.replace('_predictions.csv', '')\n",
    "\n",
    "            # Create the plot\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.scatter(true_values, predicted_values, label=f'R = {r_corr:.4f}\\nRMSE = {rmse:.4f}', alpha=0.6)\n",
    "            plt.plot([min(true_values), max(true_values)], [min(true_values), max(true_values)], color='red', linestyle='--')  # Diagonal line\n",
    "\n",
    "            # Set title and labels\n",
    "            plt.title(f'{model_name}')\n",
    "            plt.xlabel('True')\n",
    "            plt.ylabel('Predicted')\n",
    "            \n",
    "            # Show the legend with R and RMSE\n",
    "            plt.legend(loc='lower right')\n",
    "\n",
    "            # Show the plot\n",
    "            plt.grid(True)            \n",
    "            # Save the plot as a PNG file\n",
    "            plot_filename = f\"{model_name}_plot.png\"\n",
    "            plot_path = os.path.join(directory, plot_filename)\n",
    "            plt.savefig(plot_path)\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"Plot saved to {plot_path}\")\n",
    "\n",
    "def combine_plots_to_pdf(directory):\n",
    "    \"\"\"\n",
    "    Searches the specified directory for PNG files and combines them into a single PDF file.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): The path to the directory containing the PNG plot files.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store paths of PNG files\n",
    "    image_paths = []\n",
    "\n",
    "    # Search for PNG files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.png'):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            image_paths.append(image_path)\n",
    "\n",
    "    # Combine the images into a single PDF\n",
    "    if image_paths:\n",
    "        images = []\n",
    "        for image_path in image_paths:\n",
    "            img = Image.open(image_path)\n",
    "\n",
    "            # Convert image to 'RGB' mode if not already\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            images.append(img)\n",
    "\n",
    "        # Save the first image and append the rest into a PDF\n",
    "        pdf_path = os.path.join(directory, 'all_plots.pdf')\n",
    "        images[0].save(pdf_path, save_all=True, append_images=images[1:])\n",
    "        print(f\"All plots combined and saved to {pdf_path}\")\n",
    "    else:\n",
    "        print(\"No PNG plot files found.\")\n",
    "\n",
    "# Main workflow\n",
    "if __name__ == '__main__':\n",
    "    directory_path = '../Results' \n",
    "\n",
    "    # Merge the metrics and save to CSV\n",
    "    merge_metrics(directory_path)\n",
    "\n",
    "    # Plot all prediction files and save them as PNG\n",
    "    plot_predictions(directory_path)\n",
    "\n",
    "    # Combine all the PNG plots into a single PDF\n",
    "    combine_plots_to_pdf(directory_path)"
   ],
   "id": "e3a2b4e698dcafa7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged metrics saved to ../Results\\merged_metrics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shark\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ../Results\\Linear_Regression_plot.png\n",
      "Plot saved to ../Results\\Random Forest_plot.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shark\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shark\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ../Results\\SVR_plot.png\n",
      "All plots combined and saved to ../Results\\all_plots.pdf\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d1ec13ef156979d5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
